{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from fast_bert.prediction import BertClassificationPredictor\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(target, predictions):\n",
    "    \n",
    "    target = target.copy(deep=True)\n",
    "    \n",
    "    target['N'] = np.where(target['30d_unplan_readmit'] == 'N', 1, 0)\n",
    "    target['Y'] = np.where(target['30d_unplan_readmit'] == 'Y', 1, 0)\n",
    "    target = target[['N','Y']]\n",
    "    \n",
    "    np_gold = target.to_numpy()\n",
    "    np_preds = predictions.to_numpy()\n",
    "    \n",
    "    roc_auc = roc_auc_score(np_gold, np_preds, average=None)\n",
    "    \n",
    "    return np.average(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(target, predictions):\n",
    "    \n",
    "    predictions = predictions.copy(deep=True)\n",
    "    \n",
    "    predictions['30d_unplan_readmit']= np.where((predictions['Y']>0.5) & (predictions['Y']>=predictions['N']), 'Y', 'N')\n",
    "    predictions = predictions[['30d_unplan_readmit']]\n",
    "    \n",
    "    np_gold = target.to_numpy()\n",
    "    np_preds = predictions.to_numpy()\n",
    "    \n",
    "    return accuracy_score(np_gold, np_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(target, predictions):\n",
    "    \n",
    "    predictions = predictions.copy(deep=True)\n",
    "    target = target.copy(deep=True)\n",
    "\n",
    "    target['30d_unplan_readmit'] = target['30d_unplan_readmit'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "    predictions['30d_unplan_readmit']= np.where((predictions['Y']>0.5) & (predictions['Y']>=predictions['N']), 1, 0)\n",
    "    predictions = predictions[['30d_unplan_readmit']]\n",
    "    \n",
    "    np_gold = target.to_numpy()\n",
    "    np_preds = predictions.to_numpy()\n",
    "        \n",
    "    return precision_recall_fscore_support(np_gold, np_preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path('data/readmission_prediction/low_resource')\n",
    "LABEL_PATH = BASE\n",
    "TRANSFORMER = 'transformer'\n",
    "\n",
    "#path_to_directory=\"combined\"\n",
    "#model=\"biobert\"\n",
    "\n",
    "def infer(path_to_directory, model):\n",
    "\n",
    "    DATA_PATH = BASE/TRANSFORMER/path_to_directory\n",
    "    OUTPUT_DIR = BASE/TRANSFORMER/path_to_directory/'output'/model\n",
    "    MODEL_PATH = OUTPUT_DIR/'model_out'\n",
    "\n",
    "    test_dataset = pd.read_csv(DATA_PATH/'test.csv')\n",
    "    test_text = list(test_dataset['text'].values)\n",
    "\n",
    "    gold = test_dataset.drop(['text'],axis=1)\n",
    "    gold = gold.reindex(sorted(gold.columns), axis=1)\n",
    "\n",
    "    predictor = BertClassificationPredictor(model_path=MODEL_PATH,\n",
    "                                            label_path=LABEL_PATH,\n",
    "                                            multi_label=True,\n",
    "                                            model_type='bert',\n",
    "                                            do_lower_case=True)\n",
    "\n",
    "    predictions = predictor.predict_batch(test_text)\n",
    "    df_predictions=pd.DataFrame(predictions)\n",
    "    df_predictions.to_csv(OUTPUT_DIR/'predictions.csv')\n",
    "\n",
    "    preds = pd.DataFrame([{item[0]: item[1] for item in pred} for pred in predictions])\n",
    "\n",
    "    del predictor\n",
    "    del predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    auc = compute_auc(gold, preds)\n",
    "    accuracy = compute_accuracy(gold, preds)\n",
    "    f_scores = compute_f1(gold, preds)\n",
    "    precision = f_scores[0]\n",
    "    recall = f_scores[1]\n",
    "    f1 = f_scores[2]\n",
    "    \n",
    "    metrics=pd.DataFrame([{'Model': path_to_directory + '_' + model}])\n",
    "    metrics['AUC'] = auc\n",
    "    metrics['accuracy'] = accuracy\n",
    "    metrics['precision'] = precision\n",
    "    metrics['recall'] = recall\n",
    "    metrics['F1'] = f1\n",
    "    \n",
    "    metrics.to_csv(OUTPUT_DIR/'metrics.csv', index = False)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa5118/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model       AUC  accuracy  precision  recall   F1\n",
      "0  synthetic_biobert  0.527269  0.816216        0.0     0.0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa5118/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model       AUC  accuracy  precision  recall   F1\n",
      "0  synthetic_bert  0.504772  0.816216        0.0     0.0  0.0\n",
      "              Model       AUC  accuracy  precision    recall        F1\n",
      "0  combined_biobert  0.527464  0.616216   0.196721  0.352941  0.252632\n",
      "           Model       AUC  accuracy  precision  recall   F1\n",
      "0  combined_bert  0.459875  0.816216        0.0     0.0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa5118/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for directory in ['synthetic','combined']:\n",
    "#for directory in ['original','original_2x','synthetic','combined','original_eda']:\n",
    "    for model in ['biobert','bert']:\n",
    "        print(infer(directory, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_metrics = pd.DataFrame(columns=[\"Model\", \"AUC\", \"accuracy\", \"precision\", \"recall\", \"F1\"])\n",
    "#for directory in ['original','original_2x','synthetic','combined','original_eda']:\n",
    "for directory in ['synthetic','combined']:\n",
    "    for model in ['biobert','bert']:\n",
    "        csv = pd.read_csv(BASE/TRANSFORMER/directory/'output'/model/'metrics.csv')\n",
    "        global_metrics = global_metrics.append(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synthetic_biobert</td>\n",
       "      <td>0.527269</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synthetic_bert</td>\n",
       "      <td>0.504772</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>combined_biobert</td>\n",
       "      <td>0.527464</td>\n",
       "      <td>0.616216</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.252632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>combined_bert</td>\n",
       "      <td>0.459875</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model       AUC  accuracy  precision    recall        F1\n",
       "0  synthetic_biobert  0.527269  0.816216   0.000000  0.000000  0.000000\n",
       "0     synthetic_bert  0.504772  0.816216   0.000000  0.000000  0.000000\n",
       "0   combined_biobert  0.527464  0.616216   0.196721  0.352941  0.252632\n",
       "0      combined_bert  0.459875  0.816216   0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_metrics.to_csv(BASE/TRANSFORMER/'global_metrics.csv', index=False)\n",
    "global_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
